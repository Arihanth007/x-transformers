{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import RDLogger\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from typing import Optional, Union, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_codes = [f'<RX_{i+1}>' for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_names = [\n",
    "    'Heteroatom alkylation and arylation',\n",
    "    'Acylation and related processes',\n",
    "    'C-C bond formation',\n",
    "    'Heterocycle formation',\n",
    "    'Protections',\n",
    "    'Deprotections',\n",
    "    'Reductions',\n",
    "    'Oxidations',\n",
    "    'Functional group conversions (FGI)',\n",
    "    'Functional group additions (FGA)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'reactants.txt', 'w') as fp:\n",
    "#     for smi in df[df['set']=='test']['products_mol'].tolist():\n",
    "#         fp.write(\"%s\\n\" % smi[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_molecules(mol_list: list) -> Union[Chem.Mol, None]:\n",
    "    try:\n",
    "        concat_mol = Chem.MolFromSmiles('.'.join([Chem.MolToSmiles(mol) for mol in mol_list]))\n",
    "        return concat_mol\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def valid_molecules(smi_list: list) -> list:\n",
    "    mol_list = []\n",
    "    for smi in smi_list:\n",
    "        mol = Chem.MolFromSmiles(Chem.CanonSmiles(smi))\n",
    "        if mol is not None:\n",
    "            mol_list.append(mol)\n",
    "        else:\n",
    "            print(f'\\nProblematic SMILES string: {smi}\\n')\n",
    "    return mol_list\n",
    "\n",
    "def partial_correct(target_list: list, predicted_list: list) -> Tuple[float, list, list]:\n",
    "    target_mols = valid_molecules(target_list)\n",
    "    predicted_mols = valid_molecules(predicted_list)\n",
    "\n",
    "    if len(target_mols) == 0 or len(predicted_mols) == 0:\n",
    "        print(f'\\nThe molecule was not legit xD\\n')\n",
    "        print(f'Target SMILES: {target_list}')\n",
    "        print(f'Predicted SMILES: {predicted_list}\\n')\n",
    "        return 0, [], []\n",
    "\n",
    "    relevant_pred_mols = []\n",
    "    relevant_target_mols = []\n",
    "    correct = 0\n",
    "    for p_mol in predicted_mols:\n",
    "        for t_mol in target_mols:\n",
    "            if t_mol.HasSubstructMatch(p_mol) and p_mol.HasSubstructMatch(t_mol):\n",
    "                correct += 1\n",
    "                relevant_pred_mols.append(p_mol)\n",
    "                relevant_target_mols.append(t_mol)\n",
    "    \n",
    "    return correct/len(target_mols), relevant_target_mols, relevant_pred_mols\n",
    "\n",
    "def halogen_correction(target_list: list, predicted_list: list) -> Tuple[float, list, list]:\n",
    "    halogens = ['F', 'Cl', 'Br', 'I', 'At', 'Ts']\n",
    "    halogen_rep = 'I'\n",
    "\n",
    "    for halogen in halogens:\n",
    "        target_list = [smi.replace(halogen, halogen_rep) for smi in target_list]\n",
    "        predicted_list = [smi.replace(halogen, halogen_rep) for smi in predicted_list]\n",
    "\n",
    "    return partial_correct(target_list, predicted_list)\n",
    "\n",
    "def absolute_correct(target_list: list, predicted_list: list) -> bool:\n",
    "    target_mols = valid_molecules(target_list)\n",
    "    predicted_mols = valid_molecules(predicted_list)\n",
    "\n",
    "    if len(target_mols) == 0 or len(predicted_mols) == 0:\n",
    "        return False\n",
    "    target_mols = concat_molecules(target_mols)\n",
    "    predicted_mols = concat_molecules(predicted_mols)\n",
    "    if target_mols is None or predicted_mols is None:\n",
    "        return False\n",
    "    target_smi_canon = Chem.CanonSmiles(Chem.MolToSmiles(target_mols))\n",
    "    predicted_smi_canon = Chem.CanonSmiles(Chem.MolToSmiles(predicted_mols))\n",
    "    return target_smi_canon == predicted_smi_canon\n",
    "\n",
    "def tanimo_coeff(target_list: list, predicted_list: list) -> float:\n",
    "    target_mols = valid_molecules(target_list)\n",
    "    predicted_mols = valid_molecules(predicted_list)\n",
    "    target_fps = [AllChem.GetMorganFingerprintAsBitVect(x, 3, nBits=2048) for x in target_mols]\n",
    "    predicted_fps = [AllChem.GetMorganFingerprintAsBitVect(x, 3, nBits=2048) for x in predicted_mols]\n",
    "\n",
    "    tani_coeff = []\n",
    "    for p_fp in predicted_fps:\n",
    "        tani_list = DataStructs.BulkTanimotoSimilarity(p_fp, target_fps)\n",
    "        if tani_list is not None:\n",
    "            tani_list = sorted(tani_list, reverse=True)\n",
    "            tani_coeff.append(tani_list[0])\n",
    "    tani_coeff = sorted(tani_coeff, reverse=True)\n",
    "\n",
    "    t_len, p_len = len(target_fps), len(predicted_fps)\n",
    "    if t_len > p_len:\n",
    "        return sum(tani_coeff)/t_len\n",
    "    else:\n",
    "        return sum(tani_coeff[:t_len])/t_len\n",
    "\n",
    "def tanimo_coeff_concat(target_list: list, predicted_list: list) -> float:\n",
    "    target_mols = valid_molecules(target_list)\n",
    "    predicted_mols = valid_molecules(predicted_list)\n",
    "    target_mol_concat = concat_molecules(target_mols)\n",
    "    predicted_mol_concat = concat_molecules(predicted_mols)\n",
    "\n",
    "    if target_mol_concat is not None and predicted_mol_concat is not None:\n",
    "        t_fp = AllChem.GetMorganFingerprintAsBitVect(target_mol_concat, 3, nBits=2048)\n",
    "        p_fp = AllChem.GetMorganFingerprintAsBitVect(predicted_mol_concat, 3, nBits=2048)\n",
    "        return DataStructs.TanimotoSimilarity(t_fp, p_fp)\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Benchmark():\n",
    "    def __init__(\n",
    "        self, \n",
    "        source_data: str='chemformer',\n",
    "        output_file_name: str='products_mixed.txt', \n",
    "        input_file_name: Optional[str]='tgt-test.txt'\n",
    "        ) -> None:\n",
    "        self.source_data = source_data\n",
    "        if self.source_data == 'y_g2s':\n",
    "            self.df = pd.read_csv(f'{source_data}/{output_file_name}')\n",
    "        elif self.source_data == 'chemformer':\n",
    "            self.df = pd.read_pickle(f'{source_data}/{output_file_name}')\n",
    "        elif self.source_data == 'graph2smiles':\n",
    "            self.df = pd.read_pickle(f'{source_data}/{output_file_name}')\n",
    "        self.benchmark_vals = []\n",
    "        self.problematic_points = []\n",
    "        self.reconsider_rows = []\n",
    "\n",
    "    def find_score(self, df_new: pd.DataFrame, isRet: bool=False):\n",
    "        for index, row in df_new.iterrows():\n",
    "            try:\n",
    "                # self.benchmark_vals.append(halogen_correction(row['target_smiles'], row['predicted_smiles'])[0])\n",
    "                self.benchmark_vals.append(partial_correct(row['target_smiles'], row['predicted_smiles'])[0])\n",
    "            except:\n",
    "                self.benchmark_vals.append(-1)\n",
    "                self.problematic_points.append(index)\n",
    "        if isRet:\n",
    "            return self.benchmark_vals, self.problematic_points\n",
    "\n",
    "    def print_analysis(self, df_new: pd.DataFrame, df_incorrect: pd.DataFrame):\n",
    "        all_correct = 100 * df_incorrect[df_incorrect['benchmark'] == 1.0].count()[0]/(df_incorrect.count()[0])\n",
    "        half_correct = 100 * df_incorrect[df_incorrect['benchmark'].between(0.48, 0.52)].count()[0]/df_incorrect.count()[0]\n",
    "        partial_correct_abs = 100 * (df_incorrect[df_incorrect['benchmark'].between(0.48, 0.52)].count()[0] + df_incorrect[df_incorrect['benchmark'].between(0.31, 0.35)].count()[0])/df_new.count()[0]\n",
    "        a_third_correct = 100 * df_incorrect[df_incorrect['benchmark'].between(0.31, 0.35)].count()[0]/df_incorrect.count()[0]\n",
    "        initial_correct = 100 * (df_new.count()[0]-df_incorrect.count()[0])/df_new.count()[0]\n",
    "        benchmark_correct = 100 * (df_new.count()[0]-df_incorrect.count()[0]+df_incorrect[df_incorrect['benchmark'] == 1.0].count()[0])/df_new.count()[0]\n",
    "        \n",
    "        print(f'Initial performance of the model (accuracy): {initial_correct:2.2f}%')\n",
    "        print(f'Our benchmarked performance of the model (accuracy): {benchmark_correct:2.2f}%')\n",
    "        print('-'*100)\n",
    "        print(f'Percent improve in performance using our metric: {benchmark_correct-initial_correct:2.2f}%')\n",
    "        print(f'Relative perecent improve in performance using our metric: {100*(benchmark_correct-initial_correct)/initial_correct:2.2f}%')\n",
    "        print('-'*100)\n",
    "        print(f'Partial correct increase in incorrectly classified datapoints: {partial_correct_abs:2.2f}%')\n",
    "        print(f'Percent increase in all correct samples from incorrectly classified samples: {all_correct:2.2f}%')\n",
    "        print(f'Percent increase in partially correct (half-correct) samples from incorrectly classified samples: {half_correct:2.2f}%')\n",
    "        print(f'Percent increase in partially correct (one-third-correct) samples from incorrectly classified samples: {a_third_correct:2.2f}%')\n",
    "\n",
    "    def preprocess_df(self):\n",
    "        if self.source_data == 'y_g2s':\n",
    "            self.df_new = self.df.drop(columns=['target_smiles_2d', 'predicted_smiles_2d', '!correct_prediction and tanimoto_coeff > 0\\.9'])\n",
    "            self.df_new['target_smiles'] = self.df_new.apply(lambda x: x['target_smiles'].split('.'), axis=1)\n",
    "            self.df_new['predicted_smiles'] = self.df_new.apply(lambda x: x['predicted_smiles'].split('.'), axis=1)\n",
    "        \n",
    "        elif self.source_data == 'chemformer':\n",
    "            self.df.rename(columns={'original_smiles': 'target_smiles', 'prediction_0': 'predicted_smiles'}, inplace=True)\n",
    "            self.df_new = self.df.drop(columns=self.df.columns.tolist()[3:])\n",
    "            self.df_new['target_smiles'] = self.df_new.apply(lambda x: x['target_smiles'].split('.'), axis=1)\n",
    "            self.df_new['predicted_smiles'] = self.df_new.apply(lambda x: x['predicted_smiles'].split('.'), axis=1)\n",
    "        \n",
    "        elif self.source_data == 'graph2smiles':\n",
    "            self.df_new = self.df.copy()\n",
    "            self.df_new['target_smiles'] = self.df_new.apply(lambda x: x['target_smiles'][0].split('.'), axis=1)\n",
    "            self.df_new['predicted_smiles'] = self.df_new.apply(lambda x: x['predicted_smiles'][0].split('.') if len(x['predicted_smiles']) else [], axis=1)\n",
    "        \n",
    "        self.df_new['num_targets'] = self.df_new.apply(lambda x: len(x['target_smiles']), axis=1)\n",
    "        self.df_new['num_preds'] = self.df_new.apply(lambda x: len(x['predicted_smiles']), axis=1)\n",
    "\n",
    "    def benchmark(self, find_tanimoto: Optional[bool]= False):\n",
    "        self.df_new['benchmark'] = self.benchmark_vals\n",
    "        if self.source_data == 'chemformer' or self.source_data == 'graph2smiles':\n",
    "            self.df_new['correct_prediction'] = self.df_new.apply(lambda x: absolute_correct(x['target_smiles'], x['predicted_smiles']) if x['benchmark'] != -1 else False, axis=1)\n",
    "        if find_tanimoto:\n",
    "            self.df_new['tanimoto_coeff'] = self.df_new.apply(lambda x: tanimo_coeff_concat(x['target_smiles'], x['predicted_smiles']) if x['benchmark'] != -1 else 0.0, axis=1)\n",
    "        self.df_incorrect = self.df_new[self.df_new['correct_prediction'] == False]\n",
    "\n",
    "        self.print_analysis(self.df_new, self.df_incorrect)\n",
    "\n",
    "    def find_abnormal_entries(self):\n",
    "        self.decide_factor = 3\n",
    "\n",
    "        for index, row in self.df_new.iterrows():\n",
    "            t_lens = [len(smi) if len(smi) else 0 for smi in row['target_smiles']]\n",
    "            p_lens = [len(smi) if len(smi) else 0 for smi in row['predicted_smiles']]\n",
    "            try:\n",
    "                t_largest = max(t_lens)\n",
    "                p_largest = max(p_lens)\n",
    "                t_smallest = min(t_lens)\n",
    "                p_smallest = min(p_lens)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "\n",
    "            t_mols, p_mols = [], []\n",
    "            try:\n",
    "                p_mols.append(sorted([Chem.CanonSmiles(smi) for smi in row['predicted_smiles']], key=lambda s: len(s)))\n",
    "                t_mols.append(sorted([Chem.CanonSmiles(smi) for smi in row['target_smiles']], key=lambda s: len(s)))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            # if t_smallest <= 3 or t_largest/p_largest >= self.decide_factor or p_largest/t_largest >= self.decide_factor:\n",
    "            #     reconsider_rows.append(row)\n",
    "\n",
    "            if t_smallest <= 3 and t_mols[0][0] != p_mols[0][0]:\n",
    "                self.reconsider_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPTO_50k = Benchmark(source_data='chemformer', output_file_name='chemformer_pred_test_50.pickle')\n",
    "USPTO_50k.preprocess_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "USPTO_50k.find_score(USPTO_50k.df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "USPTO_50k.find_abnormal_entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial performance of the model (accuracy): 53.30%\n",
      "Our benchmarked performance of the model (accuracy): 54.52%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Percent improve in performance using our metric: 1.22%\n",
      "Relative perecent improve in performance using our metric: 2.29%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Partial correct increase in incorrectly classified datapoints: 10.59%\n",
      "Percent increase in all correct samples from incorrectly classified samples: 2.61%\n",
      "Percent increase in partially correct (half-correct) samples from incorrectly classified samples: 22.42%\n",
      "Percent increase in partially correct (one-third-correct) samples from incorrectly classified samples: 0.26%\n"
     ]
    }
   ],
   "source": [
    "USPTO_50k.benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(USPTO_50k.problematic_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of problematic points: 125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nNumber of problematic points: {len(USPTO_50k.reconsider_rows)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.471622701838529"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * USPTO_50k.df_new['benchmark'][USPTO_50k.df_new['benchmark'].between(0.48, 0.52)].count() / USPTO_50k.df_new['benchmark'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524, 5004)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USPTO_50k.df_new['benchmark'][USPTO_50k.df_new['benchmark'].between(0.48, 0.52)].count(), USPTO_50k.df_new['benchmark'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph2Smiles = Benchmark(source_data='graph2smiles', output_file_name='USPTO_50k_g2s_result.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph2Smiles.preprocess_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "Graph2Smiles.find_score(Graph2Smiles.df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "Graph2Smiles.find_abnormal_entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial performance of the model (accuracy): 51.25%\n",
      "Our benchmarked performance of the model (accuracy): 57.30%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Percent improve in performance using our metric: 6.05%\n",
      "Relative perecent improve in performance using our metric: 11.81%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Percent increase in all correct samples from incorrectly classified samples: 12.41%\n",
      "Percent increase in partially correct (half-correct) samples from incorrectly classified samples: 16.39%\n",
      "Percent increase in partially correct (one-third-correct) samples from incorrectly classified samples: 0.04%\n"
     ]
    }
   ],
   "source": [
    "Graph2Smiles.benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Graph2Smiles.problematic_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of problemactic points: 116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nNumber of problematic points: {len(Graph2Smiles.reconsider_rows)}\\n')\n",
    "# for row in Graph2Smiles.reconsider_rows:\n",
    "#     print(f'{row}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_smiles</th>\n",
       "      <th>predicted_smiles</th>\n",
       "      <th>num_targets</th>\n",
       "      <th>num_preds</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>correct_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CC(=O)c1ccc2[nH]ccc2c1, CC(C)(C)OC(=O)OC(=O)O...</td>\n",
       "      <td>[CC(O)c1ccc2c(ccn2C(=O)OC(C)(C)C)c1]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CC(C)(C)OC(=O)OC(=O)OC(C)(C)C, Cc1ccc(S(=O)(=...</td>\n",
       "      <td>[CC(C)(C)OC(=O)N1C[C@H](O)[C@@H]2OC[C@H](O)[C@...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CCOC(=O)c1nn(-c2ccc(Cl)cc2Cl)c(-c2ccc(OC)cc2)...</td>\n",
       "      <td>[CCOC(=O)c1nn(-c2ccc(Cl)cc2Cl)c(-c2ccc(OC)cc2)...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CC(C)(C)OC(=O)OC(=O)OC(C)(C)C, N#Cc1cc(-c2ccc...</td>\n",
       "      <td>[CC(C)(C)OC(=O)Nc1nc2c(-c3cccc([N+](=O)[O-])c3...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NCc1ccccc1S(=O)(=O)C1CC1, O=C(OC(=O)C(F)(F)F)...</td>\n",
       "      <td>[O=C(NCc1ccccc1S(=O)O)C(F)(F)F, O=S([O-])C1CC1]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>[C=C(C)C(=O)Cl, OCc1ccc2cc(O)ccc2c1]</td>\n",
       "      <td>[C=C(C)C(=O)O, Oc1ccc2cc(CCl)ccc2c1]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>[C[C@H]1CN(C(=O)COc2ccc(Cl)cc2)C[C@@H](C)N1, F...</td>\n",
       "      <td>[C[C@H]1CNC[C@@H](C)N1Cc1ccc(F)cc1, O=C(O)COc1...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>[CCCCc1n[nH]c(=O)n1Cc1ccc(-c2ccccc2C#N)cc1, CO...</td>\n",
       "      <td>[CCCCc1n[nH]c(=O)n1Cc1ccc(-c2ccccc2C#N)cc1, CO...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>[CCOC(=O)c1c2n(c3cc(Br)c(F)cc3c1=O)CCS2]</td>\n",
       "      <td>[CCOC(=O)c1c2n(c3cc(Br)c(F)cc3c1=O)CCS2]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>[COCCOCCOCCOCCOCCOCCOCCOCCOCCOCc1ccccc1]</td>\n",
       "      <td>[COCCOCCOCCOCCOCCOCCOCCOCCOCCOCc1ccccc1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5007 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          target_smiles  \\\n",
       "0     [CC(=O)c1ccc2[nH]ccc2c1, CC(C)(C)OC(=O)OC(=O)O...   \n",
       "1     [CC(C)(C)OC(=O)OC(=O)OC(C)(C)C, Cc1ccc(S(=O)(=...   \n",
       "2     [CCOC(=O)c1nn(-c2ccc(Cl)cc2Cl)c(-c2ccc(OC)cc2)...   \n",
       "3     [CC(C)(C)OC(=O)OC(=O)OC(C)(C)C, N#Cc1cc(-c2ccc...   \n",
       "4     [NCc1ccccc1S(=O)(=O)C1CC1, O=C(OC(=O)C(F)(F)F)...   \n",
       "...                                                 ...   \n",
       "5002               [C=C(C)C(=O)Cl, OCc1ccc2cc(O)ccc2c1]   \n",
       "5003  [C[C@H]1CN(C(=O)COc2ccc(Cl)cc2)C[C@@H](C)N1, F...   \n",
       "5004  [CCCCc1n[nH]c(=O)n1Cc1ccc(-c2ccccc2C#N)cc1, CO...   \n",
       "5005           [CCOC(=O)c1c2n(c3cc(Br)c(F)cc3c1=O)CCS2]   \n",
       "5006           [COCCOCCOCCOCCOCCOCCOCCOCCOCCOCc1ccccc1]   \n",
       "\n",
       "                                       predicted_smiles  num_targets  \\\n",
       "0                  [CC(O)c1ccc2c(ccn2C(=O)OC(C)(C)C)c1]            2   \n",
       "1     [CC(C)(C)OC(=O)N1C[C@H](O)[C@@H]2OC[C@H](O)[C@...            2   \n",
       "2     [CCOC(=O)c1nn(-c2ccc(Cl)cc2Cl)c(-c2ccc(OC)cc2)...            2   \n",
       "3     [CC(C)(C)OC(=O)Nc1nc2c(-c3cccc([N+](=O)[O-])c3...            2   \n",
       "4       [O=C(NCc1ccccc1S(=O)O)C(F)(F)F, O=S([O-])C1CC1]            2   \n",
       "...                                                 ...          ...   \n",
       "5002               [C=C(C)C(=O)O, Oc1ccc2cc(CCl)ccc2c1]            2   \n",
       "5003  [C[C@H]1CNC[C@@H](C)N1Cc1ccc(F)cc1, O=C(O)COc1...            2   \n",
       "5004  [CCCCc1n[nH]c(=O)n1Cc1ccc(-c2ccccc2C#N)cc1, CO...            2   \n",
       "5005           [CCOC(=O)c1c2n(c3cc(Br)c(F)cc3c1=O)CCS2]            1   \n",
       "5006           [COCCOCCOCCOCCOCCOCCOCCOCCOCCOCc1ccccc1]            1   \n",
       "\n",
       "      num_preds  benchmark  correct_prediction  \n",
       "0             1        0.0               False  \n",
       "1             2        0.0               False  \n",
       "2             2        1.0                True  \n",
       "3             2        0.0               False  \n",
       "4             2        0.0               False  \n",
       "...         ...        ...                 ...  \n",
       "5002          2        0.0               False  \n",
       "5003          2        0.0               False  \n",
       "5004          2        1.0                True  \n",
       "5005          1        1.0                True  \n",
       "5006          1        1.0                True  \n",
       "\n",
       "[5007 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graph2Smiles.df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_smiles</th>\n",
       "      <th>predicted_smiles</th>\n",
       "      <th>log_likelihood_0</th>\n",
       "      <th>num_targets</th>\n",
       "      <th>num_preds</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>correct_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[C1=COCCC1, COC(=O)CCC(=O)c1ccc(O)cc1O]</td>\n",
       "      <td>[C1=COCCC1, COC(=O)CCC(=O)c1ccc(O)cc1O]</td>\n",
       "      <td>-0.660116</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[COC(=O)c1cccc(C(=O)O)c1, Nc1cccnc1N]</td>\n",
       "      <td>[COC(=O)c1cccc(C(=O)O)c1, Nc1cccnc1N]</td>\n",
       "      <td>-0.669613</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CC(C)(C)OC(=O)NC1CCC(C(=O)O)CC1, CNOC]</td>\n",
       "      <td>[CC(C)(C)OC(=O)NC1CCC(C(=O)O)CC1, CNOC]</td>\n",
       "      <td>-0.628202</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Nc1ccc(O)cc1, O=[N+]([O-])c1ccc(Cl)nc1Cl]</td>\n",
       "      <td>[Nc1ccc(O)cc1, O=[N+]([O-])c1ccc(Cl)nc1Cl]</td>\n",
       "      <td>-0.679155</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[N-]=[N+]=NCC1=CC[C@@H](c2ccc(Cl)cc2Cl)[C@H](...</td>\n",
       "      <td>[C1(CN=[N+]=[N-])=CC[C@@H](c2c(Cl)cc(Cl)cc2)[C...</td>\n",
       "      <td>-3.970532</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>[Cc1cc([N+](=O)[O-])ccc1O, Nc1cc(Cl)ccn1]</td>\n",
       "      <td>[Cc1cc([N+](=O)[O-])ccc1O, Nc1cc(Cl)ccn1]</td>\n",
       "      <td>-0.692022</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>[COC(=O)c1[nH]c2cc(Cl)cc3c2c1C(CC(=O)OC(C)(C)C...</td>\n",
       "      <td>[COC(=O)c1[nH]c2cc(Cl)cc3c2c1C(CC(=O)OC(C)(C)C...</td>\n",
       "      <td>-0.709788</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>[COc1cc(C(F)(F)F)cc(SC)c1C(=O)NC1(c2ccccc2)CC(...</td>\n",
       "      <td>[C=O, COc1cc(C(F)(F)F)cc(SC)c1C(=O)NC1(c2ccccc...</td>\n",
       "      <td>-0.661519</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>[C=C(C)Cn1nc(C)c(Br)c1-c1ccc(F)cc1, OO]</td>\n",
       "      <td>[COC(=O)C(C)Cn1nc(C)c(Br)c1-c1ccc(F)cc1]</td>\n",
       "      <td>-0.876032</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>[COC(=O)c1cc(Br)c(F)c(F)c1Nc1ccccc1F, COc1ccc(...</td>\n",
       "      <td>[COC(=O)c1cc(Br)c(F)c(F)c1Nc1ccccc1F, COc1ccc(...</td>\n",
       "      <td>-0.679832</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5004 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          target_smiles  \\\n",
       "0               [C1=COCCC1, COC(=O)CCC(=O)c1ccc(O)cc1O]   \n",
       "1                 [COC(=O)c1cccc(C(=O)O)c1, Nc1cccnc1N]   \n",
       "2               [CC(C)(C)OC(=O)NC1CCC(C(=O)O)CC1, CNOC]   \n",
       "3            [Nc1ccc(O)cc1, O=[N+]([O-])c1ccc(Cl)nc1Cl]   \n",
       "4     [[N-]=[N+]=NCC1=CC[C@@H](c2ccc(Cl)cc2Cl)[C@H](...   \n",
       "...                                                 ...   \n",
       "4999          [Cc1cc([N+](=O)[O-])ccc1O, Nc1cc(Cl)ccn1]   \n",
       "5000  [COC(=O)c1[nH]c2cc(Cl)cc3c2c1C(CC(=O)OC(C)(C)C...   \n",
       "5001  [COc1cc(C(F)(F)F)cc(SC)c1C(=O)NC1(c2ccccc2)CC(...   \n",
       "5002            [C=C(C)Cn1nc(C)c(Br)c1-c1ccc(F)cc1, OO]   \n",
       "5003  [COC(=O)c1cc(Br)c(F)c(F)c1Nc1ccccc1F, COc1ccc(...   \n",
       "\n",
       "                                       predicted_smiles  log_likelihood_0  \\\n",
       "0               [C1=COCCC1, COC(=O)CCC(=O)c1ccc(O)cc1O]         -0.660116   \n",
       "1                 [COC(=O)c1cccc(C(=O)O)c1, Nc1cccnc1N]         -0.669613   \n",
       "2               [CC(C)(C)OC(=O)NC1CCC(C(=O)O)CC1, CNOC]         -0.628202   \n",
       "3            [Nc1ccc(O)cc1, O=[N+]([O-])c1ccc(Cl)nc1Cl]         -0.679155   \n",
       "4     [C1(CN=[N+]=[N-])=CC[C@@H](c2c(Cl)cc(Cl)cc2)[C...         -3.970532   \n",
       "...                                                 ...               ...   \n",
       "4999          [Cc1cc([N+](=O)[O-])ccc1O, Nc1cc(Cl)ccn1]         -0.692022   \n",
       "5000  [COC(=O)c1[nH]c2cc(Cl)cc3c2c1C(CC(=O)OC(C)(C)C...         -0.709788   \n",
       "5001  [C=O, COc1cc(C(F)(F)F)cc(SC)c1C(=O)NC1(c2ccccc...         -0.661519   \n",
       "5002           [COC(=O)C(C)Cn1nc(C)c(Br)c1-c1ccc(F)cc1]         -0.876032   \n",
       "5003  [COC(=O)c1cc(Br)c(F)c(F)c1Nc1ccccc1F, COc1ccc(...         -0.679832   \n",
       "\n",
       "      num_targets  num_preds  benchmark  correct_prediction  \n",
       "0               2          2        1.0                True  \n",
       "1               2          2        1.0                True  \n",
       "2               2          2        1.0                True  \n",
       "3               2          2        1.0                True  \n",
       "4               1          1        1.0                True  \n",
       "...           ...        ...        ...                 ...  \n",
       "4999            2          2        1.0                True  \n",
       "5000            1          1        1.0                True  \n",
       "5001            1          2        0.0               False  \n",
       "5002            2          1        0.0               False  \n",
       "5003            2          2        1.0                True  \n",
       "\n",
       "[5004 rows x 7 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USPTO_50k.df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPTO_50k_targets = set(USPTO_50k.df_new.apply(lambda x: Chem.CanonSmiles('.'.join(x['target_smiles'])), axis=1).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph2Smiles_targets = set(Graph2Smiles.df_new.apply(lambda x: Chem.CanonSmiles('.'.join(x['target_smiles'])), axis=1).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_targets = USPTO_50k_targets.intersection(Graph2Smiles_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph2Smiles.df_new.apply(lambda x: Chem.CanonSmiles('.'.join(x['target_smiles'])), axis=1).to_csv('g2s_target.txt', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_g2s(filename):\n",
    "    with open(filename) as file:\n",
    "        g2s_input = [line.rstrip() for line in file]\n",
    "\n",
    "    g2s_input = [Chem.CanonSmiles(''.join(smile.split(' '))) for smile in g2s_input]\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        for line in g2s_input:\n",
    "            f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format_g2s('./g2s_input.txt')\n",
    "format_g2s('./g2s_target.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_G2S = Benchmark(source_data='y_g2s', output_file_name='wandb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_G2S.preprocess_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "Y_G2S.find_score(Y_G2S.df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "Y_G2S.find_abnormal_entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial performance of the model (accuracy): 24.48%\n",
      "Our benchmarked performance of the model (accuracy): 26.30%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Percent improve in performance using our metric: 1.82%\n",
      "Relative perecent improve in performance using our metric: 7.43%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Percent increase in all correct samples from incorrectly classified samples: 2.41%\n",
      "Percent increase in partially correct (half-correct) samples from incorrectly classified samples: 16.86%\n",
      "Percent increase in partially correct (one-third-correct) samples from incorrectly classified samples: 0.08%\n"
     ]
    }
   ],
   "source": [
    "Y_G2S.benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of problemactic points: 105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nNumber of problematic points: {len(Y_G2S.reconsider_rows)}\\n')\n",
    "# for row in Y_G2S.reconsider_rows:\n",
    "#     print(f'{row}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[39m.\u001b[39mcolumns\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = df['reactants_mol'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = ['Ic1ccc(Nc2ncnc3cc(OCCN4CCNCC4)c(OC4CCCC4)cc23)cc1Br', 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halogen_correction(test_target, test_pred)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tanimo_coeff(test_target, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tanimo_coeff_concat(test_target, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('wandb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(r'products_mixed.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'original_smiles': 'target_smiles', 'prediction_0': 'predicted_smiles'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.drop(columns=df.columns.tolist()[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = df_new.drop(columns=['target_smiles_2d', 'predicted_smiles_2d', '!correct_prediction and tanimoto_coeff > 0\\.9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['target_smiles'] = df_new.apply(lambda x: x['target_smiles'].split('.'), axis=1)\n",
    "df_new['predicted_smiles'] = df_new.apply(lambda x: x['predicted_smiles'].split('.'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.MolFromSmarts(df_new.iloc[0]['predicted_smiles'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "benchmark_vals = []\n",
    "problematic_points = []\n",
    "for index, row in df_new.iterrows():\n",
    "    try:\n",
    "        benchmark_vals.append(halogen_correction(row['target_smiles'], row['predicted_smiles'])[0])\n",
    "    except:\n",
    "        benchmark_vals.append(-1)\n",
    "        problematic_points.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(problematic_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['benchmark'] = benchmark_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['tanimoto_coeff'] = df_new.apply(lambda x: tanimo_coeff_concat(x['target_smiles'], x['predicted_smiles']) if x['benchmark'] != -1 else 0.0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['correct_prediction'] = df_new.apply(lambda x: absolute_correct(x['target_smiles'], x['predicted_smiles']) if x['benchmark'] != -1 else False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incorrect = df_new[df_new['correct_prediction'] == False]\n",
    "# df_incorrect = df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incorrect.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incorrect[df_incorrect['benchmark'] == 1.0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incorrect[df_incorrect['benchmark'] == 1.0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 2\n",
    "Draw.MolsToGridImage([Chem.MolFromSmiles(df_incorrect[df_incorrect['benchmark'] == 1.0].iloc[ii]['target_smiles'][0]), Chem.MolFromSmiles(df_incorrect[df_incorrect['benchmark'] == 1.0].iloc[ii]['predicted_smiles'][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incorrect[df_incorrect['benchmark'] >= 0.5].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incorrect[df_incorrect['benchmark'] >= 0.32].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_correct = 100 * df_incorrect[df_incorrect['benchmark'] == 1.0].count()[0]/(df_incorrect.count()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_correct = 100 * df_incorrect[df_incorrect['benchmark'] >= 0.5].count()[0]/df_incorrect.count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_third_correct = 100 * df_incorrect[df_incorrect['benchmark'] >= 0.32].count()[0]/df_incorrect.count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_correct = 100 * (df_new.count()[0]-df_incorrect.count()[0])/df_new.count()[0]\n",
    "initial_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_correct = 100 * (df_new.count()[0]-df_incorrect.count()[0]+df_incorrect[df_incorrect['benchmark'] == 1.0].count()[0])/df_new.count()[0]\n",
    "benchmark_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Initial performance of the model (accuracy): {initial_correct:2.2f}%')\n",
    "print(f'Our benchmarked performance of the model (accuracy): {benchmark_correct:2.2f}%')\n",
    "print(f'Percent improve in performance using our metric: {benchmark_correct-initial_correct:2.2f}%')\n",
    "print(f'Relative perecent improve in performance using our metric: {100*(benchmark_correct-initial_correct)/initial_correct:2.2f}%')\n",
    "print()\n",
    "print(f'Percent increase in all correct samples from incorrectly classified samples: {all_correct:2.2f}%')\n",
    "print(f'Percent increase in partially correct (half-correct) samples from incorrectly classified samples: {half_correct:2.2f}%')\n",
    "print(f'Percent increase in partially correct (one-third-correct) samples from incorrectly classified samples: {a_third_correct:2.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "reconsider_rows = []\n",
    "decide_factor = 3\n",
    "\n",
    "for index, row in df_new.iterrows():\n",
    "    t_lens = [len(smi) for smi in row['target_smiles']]\n",
    "    p_lens = [len(smi) for smi in row['predicted_smiles']]\n",
    "    t_largest = max(t_lens)\n",
    "    p_largest = max(p_lens)\n",
    "    t_smallest = min(t_lens)\n",
    "    p_smallest = min(p_lens)\n",
    "\n",
    "    t_mols, p_mols = [], []\n",
    "    try:\n",
    "        p_mols.append(sorted([Chem.CanonSmiles(smi) for smi in row['predicted_smiles']], key=lambda s: len(s)))\n",
    "        t_mols.append(sorted([Chem.CanonSmiles(smi) for smi in row['target_smiles']], key=lambda s: len(s)))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # if t_smallest <= 3 or t_largest/p_largest >= decide_factor or p_largest/t_largest >= decide_factor:\n",
    "    #     reconsider_rows.append(row)\n",
    "\n",
    "    if t_smallest <= 3 and t_mols[0][0] != p_mols[0][0]:\n",
    "        reconsider_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in reconsider_rows:\n",
    "    print(row)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bppred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c7adab5ca5842531a30133d982d8360058a2ed335d641c8cce6d20929bc464b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
