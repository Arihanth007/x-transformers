{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from mlm_pytorch.mlm_pytorch.mlm_pytorch import MLM\n",
    "from x_transformers.x_transformers import TransformerWrapper, Encoder, Decoder\n",
    "from x_transformers.autoregressive_wrapper import AutoregressiveWrapper\n",
    "from SmilesPE.pretokenizer import atomwise_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zinc(Dataset):\n",
    "    def __init__(self, data_dir: str='/scratch/arihanth.srikar', split: str='train', to_gen: int=-1):\n",
    "        extra = ''\n",
    "        \n",
    "        # dataset files\n",
    "        # df = pd.read_pickle(f'{data_dir}/x001{extra}.pickle')\n",
    "        df = pd.read_csv(f'{data_dir}/x001.csv')\n",
    "        df = df[df['set'] == split].copy()\n",
    "        \n",
    "        # read entire dataset and convert to list\n",
    "        self.smiles = df['smiles'].tolist()\n",
    "        \n",
    "        # clear memory\n",
    "        del df\n",
    "        \n",
    "        # load specified number of samples\n",
    "        self.to_gen = to_gen if to_gen > 0 else len(self.smiles)\n",
    "        \n",
    "        # token encoder and decoder\n",
    "        with open(f'{data_dir}/vocab{extra}.txt', 'r') as f:\n",
    "            self.token_decoder = f.read().splitlines()\n",
    "        self.token_encoder = {k: v for v, k in enumerate(self.token_decoder)}\n",
    "\n",
    "        self.vocab_size = len(self.token_decoder)\n",
    "        self.pad_token_id = self.token_encoder['<pad>']\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.to_gen\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # pick random indices if not utilizing entire dataset\n",
    "        if self.to_gen != len(self.smiles):\n",
    "            idx = torch.randint(0, len(self.smiles), (1,)).item()\n",
    "        \n",
    "        # treat the smiles as products\n",
    "        p = self.smiles[idx]\n",
    "        p = [self.token_encoder[tok] for tok in atomwise_tokenizer(p)]\n",
    "        \n",
    "        # append end of products token\n",
    "        p = [self.token_encoder['<sop>']] + p + [self.token_encoder['<eop>']]\n",
    "        mask = [1] * len(p)\n",
    "        \n",
    "        return torch.tensor(p), torch.tensor(mask)\n",
    "\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        smiles, mask = zip(*batch)\n",
    "        smiles = torch.nn.utils.rnn.pad_sequence(smiles, batch_first=True, padding_value=self.token_encoder['<pad>'])\n",
    "        mask = (smiles != self.token_encoder['<pad>']).bool()\n",
    "        return smiles, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Zinc(split='train', to_gen=100*384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=128, collate_fn=train_dataset.collate_fn, shuffle=True, num_workers=8, pin_memory=True, prefetch_factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles, mask = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_transformer = TransformerWrapper(\n",
    "    num_tokens = train_dataset.vocab_size,\n",
    "    max_seq_len = 512,\n",
    "    attn_layers = Encoder(\n",
    "        dim = 512,\n",
    "        depth = 6,\n",
    "        heads = 8,\n",
    "        rel_pos_bias = True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = TransformerWrapper(\n",
    "    num_tokens = train_dataset.vocab_size,\n",
    "    max_seq_len = 512,\n",
    "    attn_layers = Decoder(\n",
    "        dim = 512,\n",
    "        depth = 6,\n",
    "        heads = 8,\n",
    "        rel_pos_bias = True,\n",
    "        cross_attend = True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = MLM(\n",
    "    encoder_transformer,\n",
    "    mask_token_id = train_dataset.token_encoder['<mask>'],          # the token id reserved for masking\n",
    "    pad_token_id = train_dataset.token_encoder['<pad>'],           # the token id for padding\n",
    "    mask_prob = 0.15,           # masking probability for masked language modeling\n",
    "    replace_prob = 0.90,        # ~10% probability that token will not be masked, but included in loss, as detailed in the epaper\n",
    "    mask_ignore_token_ids = []  # other tokens to exclude from masking, include the [cls] and [sep] here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = AutoregressiveWrapper(\n",
    "    decoder,\n",
    "    pad_value = train_dataset.token_encoder['<pad>'],\n",
    "    ignore_index=train_dataset.token_encoder['<pad>'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles, mask = next(iter(train_dataloader))\n",
    "smiles.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder.cuda()\n",
    "smiles, mask = smiles.cuda(), mask.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits, enc, loss = encoder(smiles, mask=mask, return_logits_and_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.shape, enc.shape, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    decoder_logits, decoder_loss = decoder(smiles, context=enc, context_mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_logits.shape, decoder_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "optimizer = AdamW(list(encoder.parameters())+list(decoder.parameters()), lr=1e-4)\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "for epoch in range(10):\n",
    "    avg_encoder_loss, avg_decoder_loss = 0, 0\n",
    "    with tqdm(train_dataloader) as pbar:\n",
    "        pbar.set_description(f'Epoch {epoch+1}')\n",
    "        for i, (smiles, mask) in enumerate(pbar):\n",
    "            smiles, mask = smiles.to(device), mask.to(device)\n",
    "            \n",
    "            encoder_logits, enc, encoder_loss = encoder(smiles, mask=mask, return_logits_and_embeddings=True)\n",
    "            decoder_logits, decoder_loss = decoder(smiles, context=enc, context_mask=mask)\n",
    "\n",
    "            encoder_loss.backward()\n",
    "            # decoder_loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            avg_encoder_loss += encoder_loss.item()\n",
    "            avg_decoder_loss += decoder_loss.item()\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'encoder_loss': encoder_loss.item(),\n",
    "                'decoder_loss': decoder_loss.item(),\n",
    "                'avg_encoder_loss': avg_encoder_loss/(i+1),\n",
    "                'avg_decoder_loss': avg_decoder_loss/(i+1)\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
